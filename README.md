# ds-interview-qa
    
- 데이터 사이언스 / 분석 직군 관련 주요 인터뷰 질문 및 답안을 정리합니다(업데이트 중)
             
## 통계     
* Q. 샘플 비율이 불균형한 데이터를 어떻게 처리해야 할까요?
	* A. 랜덤 오버 샘플링 또는 랜덤 언더 샘플링 방법으로 데이터의 샘플 균형을 맞출 수 있습니다. 오버 샘플링은 소수 클래스에 해당하는 데이터에서 표본을 추가로 랜덤 복원 추출해서 더 많은 샘플을 얻는 방법이고, 언더 샘플링은 다수 클래스에 해당하는 데이터에서 적은 양의 데이터를 랜덤 추출해 샘플 균형을 맞추는 방법입니다. 오버 샘플링에는 대표적으로 SMOTE(Synthetic Minority Over-sampling Technique) 알고리즘이 있습니다. 소수 클래스 데이터 세트의 각 샘플에서 k-최근접 이웃 알고리즘으로 이웃한 샘플을 정하고, 두 샘플을 잇는 선상에서 새로운 합성 샘플을 랜덤으로 생성하는 방법입니다.


* Q. 확률probability과 가능도likelihood(또는 우도)는 어떻게 다를까요?
	* A. 확률은 확률분포가 주어졌을 때 관측한 데이터가 분포에서 나타날 가능성을 의미합니다. 반면 가능도는 어떤 가설을 참으로 가정했을 때 관찰한 데이터값이 나타날 가능성입니다. 즉 관측 데이터를 통해서 확률분포 값을 구하는 것입니다. 베이지안 통계학에서는 사전 확률과 가능도는 이용해 사후 확률을 계산하게 됩니다.

* Q. p-value의 의미를 설명해주세요.
	* A. 두 집단의 모수가 같다는 귀무가설과 다르다는 대립가설 중 어느 쪽이 맞는지 검증하기 위해 표본을 추출했을 때, 두 집단의 모수가 같을 가능성을 나타내는 수치라고 볼 수 있습니다. 즉 p-value의 기준을 5%라고 한다면, p-value가 5% 이상인 경우 두 모수가 같다는 귀무가설을 거짓이라고 볼 수 없습니다. 
          
                
             
## 머신러닝
* Q. 머신러닝에서 샘플링을 하는 이유는 무엇일까요?
	* A. 훈련에 들어가는 시간과 리소스가 너무 많은 경우 모든 샘플을 훈련시키지 않고 샘플링을 통해 일부 데이터만 훈련시키게 됩니다. 이 때 전체 데이터 분포를 대표할 수 있는 데이터를 훈련 세트로 추출합니다. 


* Q. 하이퍼파라미터를 최적화하는 방법을 설명해보세요.
	* A. 하이퍼파라미터를 최적화하는 방법으로는 그리드 탐색, 랜덤 탐색 방법 등이 있습니다. 그리드 탐색은 모든 샘플을 대상으로 최적값을 찾는 방법으로, 탐색 범위를 넓게, 탐색 스템을 작게 설정하는 경우 전역 최적해를 찾을 가능성이 높습니다. 랜덤 탐색은 모든 값을 테스트하지 않고 랜덤으로 선택한 값만 테스트합니다. 그리드 탐색의 경우 단 시간과 리소스가 많이 소모되는 반면 랜덤 탐색은 속도가 빠른 것이 장점입니다. 그러나 랜덤 서치는 전역 최적해를 찾을 가능성이 낮습니다.
                    
                     
* Q. 과적합을 피하는 방법은 무엇이 있을까요?
	* A.  과적합은 모델이 훈련 데이터만 잘 예측하고 테스트 데이터나 새로운 데이터는 잘 예측하지 못하는 현상입니다. 과적합을 피하기 위해서는 먼저 더 많고 다양한 데이터를 학습시켜 모델이 유효한 특성을 더 많이 학습하도록 해야 합니다. 아니면 모델의 복잡도를 낮추거나 정규화항을 추가해 과적합을 방지할 수 있습니다. 또 앙상블 학습처럼 다수의 모델을 합치는 방법으로 단일 모델의 과적합 위험을 줄일 수도 있습니다.
                      
			        
* Q. word2vec 모델에 대해서 설명해주세요.
	* A. word2vec은 단어를 벡터로 변환하는 워드 임베팅 모델입니다. CBOW 모델은 맥략을 통해서 하나의 단어를 예측하는 모델이고, skip-gram 모델은 단어를 통해서 맥락을 추측합니다. 맥락을 얼마나 반영하느냐에 따라 슬라이딩 윈도우의 크기를 정하게 됩니다. 


* Q. L1, L2 규제에 대해서 설명해주세요.
	* A. L1 규제(Lasso Regression)는 손실 함수에 가중치의 절대값인 L1 노름을, L2 규제(Ridge Regression)는 가중치의 제곱인 L2 노름을 더해 과적합을 줄입니다. L1 규제의 경우 가중치의 값이 작아지고 파라미터가 거의 0에 수렴하는 피처들도 생기게 됩니다. L2 규제에서도 가중치의 값이 작아지는데, 가중치를 제곱하기 때문에 이상치에 영향을 받을 가능성이 더 높습니다.
	

## UX/커뮤니케이션 등
* UI/UX에 대해서 설명해주세요.
    *  UI는 시각적인 디자인을 의미하고, UX는 디자인의 방법론을 일컫는 말입니다. 즉 사용자가 서비스를 편리하고 최적화된 방향으로 이용할 수 있게 하는 환경을 디자인하는 방법론이라고 할 수 있습니다.
    
    
* BI툴 중에서 선호하는 것은 무엇인고 이유는 무엇인지 설명해주세요.
* 어떤 분석이 좋은 분석이라고 생각하나요?
* 다른 팀에게 데이터 분석을 해야 하는 이유를 어떻게 설득할 수 있을까요?
* 어떤 서비스를 가정하고 문제 상황을 설정한 뒤 이를 분석을 통해 어떻게 해결할 수 있는지 설명해주세요.


